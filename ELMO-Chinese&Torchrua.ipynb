{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8615236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import gc\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc265aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chinese_embeddings(path, vocabulary, word2id, emb_size=300):\n",
    "    w_emb = np.zeros((len(word2id), emb_size))\n",
    "    with z.open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.decode('utf-8')\n",
    "            word = line.split()[0]\n",
    "                \n",
    "            if word in vocabulary: \n",
    "                try:\n",
    "                    emb = np.array(line.strip('\\n').split()[1:]).astype(np.float32)\n",
    "                    w_emb[word2id[word]] +=emb     \n",
    "                except:\n",
    "                    continue      \n",
    "    return w_emb   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1223628",
   "metadata": {},
   "source": [
    "# torchrua 真好用！！！用来pack. pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c0a13363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrua import reverse_packed_sequence, pad_packed_sequence, pack_padded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "689ead6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ELMO, self).__init__()\n",
    "        \n",
    "        self.lamda = 1\n",
    "        self.layer_weights = torch.randn(3)\n",
    "        \n",
    "        self.word_embeds = 300\n",
    "        self.hidden_dim = 300\n",
    "        \n",
    "        self.lstm_forward_1 = nn.LSTM(self.word_embeds, self.hidden_dim,\n",
    "                            num_layers=1, bidirectional=False, batch_first = True)\n",
    "        self.lstm_forward_2 = nn.LSTM(self.word_embeds, self.hidden_dim,\n",
    "                            num_layers=1, bidirectional=False, batch_first = True)\n",
    "        self.lstm_backward_1 = nn.LSTM(self.word_embeds, self.hidden_dim,\n",
    "                            num_layers=1, bidirectional=False, batch_first = True)\n",
    "        self.lstm_backward_2 = nn.LSTM(self.word_embeds, self.hidden_dim,\n",
    "                            num_layers=1, bidirectional=False, batch_first = True)\n",
    "        \n",
    "    def forward(self,sequence):\n",
    "        \n",
    "        # Get the fixed embeddings for the input batch of sequences\n",
    "        embedding_sequence = self.get_embeddings(sequence)\n",
    "        # the list to store the real length of each input\n",
    "        lengths = []\n",
    "        for i in range(batch_size):\n",
    "            lengths.append(maskings[i,:].tolist().count(1))\n",
    "        # pack the sequence to let LSTM ignoring padding\n",
    "        pack_sequence = pack_padded_sequence(embedding_sequence, torch.Tensor(lengths).long(), batch_first=True)\n",
    "        reversed_pack_sequence = reverse_packed_sequence(pack_sequence)\n",
    "        # Randomly generate hidden_states and cell_states\n",
    "        h1 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        c1 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        \n",
    "        h2 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        c2 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        \n",
    "        h3 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        c3 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        \n",
    "        h4 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        c4 = torch.randn(1, batch_size, self.hidden_dim)\n",
    "        # Forward the input through 2-layer stacked and two directional LSTM, 1st layer\n",
    "        packed_forward_output_1 = self.lstm_forward_1(embedding_sequence,(h1,c1))[0]\n",
    "        packed_backward_output_1 = self.lstm_backward_1(torch.flip(embedding_sequence, dims=[1]),(h2,c2))[0]\n",
    "        # unpack and repack\n",
    "        forward_output_1_media = pad_packed_sequence(packed_forward_output_1, batch_first=True)\n",
    "        backward_output_1_media = pad_packed_sequence(packed_backward_output_1, batch_first=True)\n",
    "        forward_output_1 = pack_padded_sequence(forward_output_1_media, torch.Tensor(lengths).long(), batch_first=True)\n",
    "        backward_output_1 = pack_padded_sequence(backward_output_1_media, torch.Tensor(lengths).long(), batch_first=True)\n",
    "        # Residual adding\n",
    "        forward_output_1 = torch.add(forward_output_1,embedding_sequence)\n",
    "        backward_output_1 = torch.add(backward_output_1,torch.flip(embedding_sequence, dims=[1]))\n",
    "        # Forward the input through 2nd layer\n",
    "        packed_forward_output_2 = self.lstm_forward_2(forward_output_1,(h3,c3))[0]\n",
    "        packed_backward_output_2 = self.lstm_backward_2(backward_output_1,(h4,c4))[0]\n",
    "        # unpack\n",
    "        forward_output_2 = pad_packed_sequence(packed_forward_output_2, batch_first=True)\n",
    "        backward_output_2 = pad_packed_sequence(packed_backward_output_2, batch_first=True)\n",
    "        # Get the outputs from the first LSTM layer and the second LSTM layer\n",
    "        double_embedding = torch.cat((embedding_sequence,embedding_sequence),1)\n",
    "        firstLayer_output = torch.cat((forward_output_1_media, torch.flip(backward_output_1_media, dims=[1])), 1)\n",
    "        secondLayer_output = torch.cat((forward_output_2, torch.flip(backward_output_2, dims=[1])), 1)\n",
    "        # Get the weighted sum of different part of word representations\n",
    "        weights = nn.Softmax(self.layer_weights)\n",
    "        weighted_representation = weights[0]*double_embedding+weights[1]*firstLayer_output,weights[2]*secondLayer_output\n",
    "                \n",
    "        return (weighted_representation,(double_embedding, firstLayer_output, secondLayer_output))\n",
    "    \n",
    "    \n",
    "    def get_embeddings(self, sequence, embeddings):\n",
    "        \n",
    "        embeddings = torch.from_numpy(embeddings)\n",
    "        emb_size = embeddings.size()[1]\n",
    "        \n",
    "        batch_size = sequence.size()[0]\n",
    "        seq_length = sequence.size()[1]\n",
    "        \n",
    "        output = torch.zeros(batch_size,seq_length,emb_size)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_length):\n",
    "                w_id = sequence[i,j]\n",
    "                output[i,j,:]+= embeddings[w_id]\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b354a1",
   "metadata": {},
   "source": [
    "# Minor Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8d44379",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e9519e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ba0ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc8f022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ada89b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0] = torch.Tensor([7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b00e542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8, 9],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f6c4d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51440c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5b201e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4611fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[t[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25adbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2,3,0,0],[4,5,0,0,0],[6,0,0,0,0]])\n",
    "l = torch.Tensor([3,2,1])\n",
    "r = torch.nn.utils.rnn.pack_padded_sequence(a, l, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f0285b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1., 4., 6., 2., 5., 3.]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.nn.utils.rnn.pack_padded_sequence(a, l, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c633dcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3., 2., 1.],\n",
       "        [0., 0., 0., 5., 4.],\n",
       "        [0., 0., 0., 0., 6.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(a,dims = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1333863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([0., 0., 0., 0., 0., 3.]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c7660d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-a674e95d3970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "g = torch.Tensor([[1,2,3],[4,5],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9f65487",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchrua'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-30390fd18462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchrua\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchrua'"
     ]
    }
   ],
   "source": [
    "import torchrua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91470a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchura (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torchura\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9912fc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_packed_sequence' from 'torch' (/Users/aooscar/anaconda/envs/py3/lib/python3.8/site-packages/torch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-b9977e713d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pad_packed_sequence' from 'torch' (/Users/aooscar/anaconda/envs/py3/lib/python3.8/site-packages/torch/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torch import pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a986b319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef9f20ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.utils.rnn' has no attribute 'reverse_packed_sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-7a77d8277fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_packed_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.utils.rnn' has no attribute 'reverse_packed_sequence'"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.rnn.reverse_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cae57633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 0, 0, 0],\n",
      "        [1, 2, 3, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchrua import reverse_packed_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "pad = pad_sequence([\n",
    "    torch.arange(5) + 1,\n",
    "    torch.arange(2) + 1,\n",
    "    torch.arange(3) + 1,\n",
    "], batch_first=True)\n",
    "lengths = torch.tensor([5, 2, 3])\n",
    "\n",
    "print(pad)\n",
    "# tensor([[1, 2, 3, 4, 5],\n",
    "#         [1, 2, 0, 0, 0],\n",
    "#         [1, 2, 3, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dc8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "edda58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack = pack_padded_sequence(pad, lengths, batch_first=True)\n",
    "reversed_pack = reverse_packed_sequence(pack)\n",
    "reversed_pad, _ = pad_packed_sequence(reversed_pack, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "620e3fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 1, 1, 2, 2, 2, 3, 3, 4, 5]), batch_sizes=tensor([3, 3, 2, 1, 1]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "caf0735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_pack = reversed_pack+reversed_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08624650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4, 3, 2, 1],\n",
       "        [2, 1, 0, 0, 0],\n",
       "        [3, 2, 1, 0, 0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "86496fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5, 3, 2, 4, 2, 1, 3, 1, 2, 1]),\n",
       " tensor([3, 3, 2, 1, 1]),\n",
       " tensor([0, 2, 1]),\n",
       " tensor([0, 2, 1]),\n",
       " tensor([5, 3, 2, 4, 2, 1, 3, 1, 2, 1]),\n",
       " tensor([3, 3, 2, 1, 1]),\n",
       " tensor([0, 2, 1]),\n",
       " tensor([0, 2, 1]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe81a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
